# ============================================================================
# RAG Chatbot Backend Environment Configuration
# Constitution v1.1.0 / Gemini 2.5 Flash Edition
# ============================================================================

# ----------------------------------------------------------------------------
# GEMINI API CONFIGURATION (RECOMMENDED FOR FREE TIER)
# ----------------------------------------------------------------------------
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# LLM Provider: "google" for Gemini, "openai" for OpenAI
LLM_PROVIDER=google

# LLM Model: Use gemini-2.5-flash for free tier
# Other options: gemini-1.5-pro, gemini-2.0-flash
LLM_MODEL=gemini-2.5-flash

# Gemini OpenAI-compatible endpoint (required for LangChain ChatOpenAI)
# No trailing slash!
LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai

# Embedding Model (Gemini text-embedding-004 = 768 dimensions)
EMBEDDING_MODEL=text-embedding-004
EMBEDDING_DIMENSION=768

# ----------------------------------------------------------------------------
# ALTERNATIVE: OPENAI CONFIGURATION
# ----------------------------------------------------------------------------
# Uncomment and fill these if using OpenAI instead of Gemini
# OPENAI_API_KEY=sk-your-openai-api-key-here
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSION=1536

# ----------------------------------------------------------------------------
# QDRANT CONFIGURATION
# ----------------------------------------------------------------------------
# Option 1: Local Qdrant (Docker)
# Run: docker run -p 6333:6333 qdrant/qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Option 2: Qdrant Cloud (uncomment and fill)
# Get your cluster URL from: https://cloud.qdrant.io
# QDRANT_URL=https://your-cluster-id.region.gcp.cloud.qdrant.io:6333
# QDRANT_API_KEY=your-qdrant-api-key-here

# Collection name for storing book content vectors
QDRANT_COLLECTION_NAME=physical_ai_book

# ----------------------------------------------------------------------------
# BOOK CONTENT PATH
# ----------------------------------------------------------------------------
# Relative path from backend directory to the docs folder
DOCS_PATH=../physical-ai-humanoid-robotics/docs

# ----------------------------------------------------------------------------
# SERVER CONFIGURATION
# ----------------------------------------------------------------------------
HOST=0.0.0.0
PORT=8000

# CORS origins (comma-separated for multiple origins)
# Add your frontend URL here
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Debug mode (set to false in production)
DEBUG=true

# ----------------------------------------------------------------------------
# OPTIONAL: DATABASE FOR SESSION PERSISTENCE
# ----------------------------------------------------------------------------
# Neon Serverless Postgres connection URL (optional)
# Get your URL from: https://neon.tech
# NEON_DATABASE_URL=postgresql://user:pass@host/dbname?sslmode=require
